# AI Document Assistant

ğŸ¤– **Sistem AI untuk melakukan tanya jawab dengan dokumen PDF menggunakan LangChain dan OpenAI API**

## ğŸ“‹ Deskripsi

AI Document Assistant adalah aplikasi yang memungkinkan pengguna untuk:

â€¢ ğŸ“„ **Memuat dan memproses dokumen PDF**  
â€¢ ğŸ” **Melakukan pencarian cerdas dalam dokumen**  
â€¢ ğŸ’¬ **Bertanya tentang isi dokumen dan mendapat jawaban yang relevan**  
â€¢ ğŸ§  **Menggunakan AI untuk memberikan jawaban yang kontekstual**

## ğŸ—ï¸ Arsitektur Agent

### Komponen Utama:

**â€¢ Prompt + Memory**
- Prompt dinamis dengan konteks dari dokumen
- Memory menggunakan pendekatan Semantic Memory (vector store FAISS)

**â€¢ Tool / Function**
- Tool utama: pencarian dokumen menggunakan vector similarity
- Tool opsional: fallback pencarian lokal (non-AI)

**â€¢ Model**
- LLM: gpt-3.5-turbo dari OpenAI
- Embedding: text-embedding-ada-002
- Vector DB: FAISS (lokal)

## ğŸ” Agent Loop (Observe â†’ Decide â†’ Act)

1. **Observe**: User menginput pertanyaan dalam bahasa natural
2. **Decide**: Sistem mencocokkan pertanyaan ke chunk dokumen terdekat (via vector search)
3. **Act**: Jawaban dihasilkan oleh LLM berdasarkan konteks dokumen

## ğŸš€ Fitur

â€¢ âœ… Memuat dokumen PDF internal  
â€¢ âœ… Preprocessing dan chunking otomatis  
â€¢ âœ… Pencarian berbasis vector  
â€¢ âœ… Integrasi OpenAI untuk QnA  
â€¢ âœ… Alternatif offline (local string matching)  
â€¢ âœ… Error handling user-friendly  

## ğŸ“ Struktur Projekt

```
ai_document_assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/              # AI Agent implementation
â”‚   â”œâ”€â”€ document_processor/  # PDF processing and chunking
â”‚   â”œâ”€â”€ vector_store/        # FAISS vector database
â”‚   â”œâ”€â”€ tools/              # Search and utility tools
â”‚   â”œâ”€â”€ memory/             # Semantic memory implementation
â”‚   â””â”€â”€ ui/                 # Streamlit web interface
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/          # PDF documents storage
â”‚   â””â”€â”€ vector_db/         # FAISS database files
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py          # Configuration settings
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env.example          # Environment variables template
â””â”€â”€ app.py                # Main application entry point
```

## ğŸ› ï¸ Installation & Setup

1. **Clone and setup environment:**
   ```bash
   git clone <repository>
   cd ai_document_assistant
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Setup environment variables:**
   ```bash
   cp .env.example .env
   # Edit .env and add your OpenAI API key
   ```

4. **Run the application:**
   ```bash
   streamlit run app.py
   ```

## ğŸ”‘ Environment Variables

Create a `.env` file with the following variables:

```env
OPENAI_API_KEY=your_openai_api_key_here
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_TOKENS=4000
TEMPERATURE=0.7
```

## ğŸ“– Usage

1. **Upload PDF Document**: Use the file uploader in the web interface
2. **Wait for Processing**: The system will chunk and index your document
3. **Ask Questions**: Type your questions in natural language
4. **Get AI Answers**: Receive contextual answers based on document content

## ğŸ§ª Testing

Run tests using pytest:
```bash
pytest tests/ -v
```

## ğŸš€ Development

The application follows a modular architecture:

- **Agent Loop**: Implemented in `src/agents/`
- **Document Processing**: Handled by `src/document_processor/`
- **Vector Search**: Managed by `src/vector_store/`
- **Memory System**: Semantic memory in `src/memory/`
- **Tools**: Search utilities in `src/tools/`

## ğŸ“Š Performance

- **Vector Search**: Sub-second response time for most queries
- **Memory Usage**: Optimized chunking for efficient storage
- **Scalability**: Supports multiple documents simultaneously

## ğŸ”§ Configuration

Adjust settings in `config/config.py`:
- Chunk size and overlap
- Model parameters
- Vector store settings
- UI customization

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

---

**Built with â¤ï¸ using LangChain, OpenAI, and FAISS**
